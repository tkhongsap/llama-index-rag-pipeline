Based on the provided sources, a Retrieval Augmented Generation (RAG) workflow typically involves two main parts: **Data Ingestion** and **Data Retrieval**. Here are the steps and components involved in each part:

**1. Data Ingestion**

This part focuses on preparing your data for the retrieval process. It involves transforming raw data into a structured format that can be effectively queried by a Language Model (LLM).

*   **Parsing**: Converting raw data, such as documents, into a usable text format. This is a crucial first step, as bad parsing can lead to poor results ("garbage in = garbage out"). Dealing with **complex documents** that contain embedded tables, charts, images, or have irregular layouts requires advanced parsing techniques, as naive methods can fail. **LlamaParse** is highlighted as a tool specifically designed for parsing complex documents and extracting structured information like tables.
*   **Chunking**: Splitting the parsed text into smaller, manageable pieces or nodes. The goal is often to preserve semantically similar content within chunks. Different strategies exist, including page-level chunking as a strong baseline, or sentence splitting. A more advanced technique involves using a **Sentence Window Node Parser** to create nodes representing single sentences, but attaching a "window" of surrounding sentences as metadata. This allows for fine-grained retrieval while providing sufficient context for the LLM during synthesis. It's also a key technique to **decouple chunks used for retrieval vs. chunks used for synthesis**.
*   **Embedding**: Creating vector representations (embeddings) for each chunk or node. These embeddings capture the semantic meaning of the text and are used for similarity search during retrieval. It's suggested that embedding references (like summaries) instead of just the raw text can improve retrieval. Having multiple embeddings pointing to the same chunk is considered a good practice. Optimizing the embedding model for your specific data corpus is also a consideration.
*   **Indexing**: Storing the chunks or nodes, along with their embeddings and associated metadata, in an index structure, typically a vector database. Different types of indexes can be built, such as a standard **VectorStoreIndex** over text nodes or a **Document Summary Index** which stores summaries of documents alongside the document's nodes. For hierarchical data, **Index Nodes** can be created to represent summaries or links to other query engines (like a Pandas query engine over a table), and these index nodes are stored in the vector index alongside text nodes. This enables recursive retrieval.

**2. Data Retrieval**

This part involves taking a user's natural language query and using the prepared index to find and return the most relevant information.

*   **Query Input**: Receiving the user's request or question.
*   **Retrieval Logic**: Utilizing the user query to search the index and retrieve relevant nodes or chunks. While basic top-k retrieval is a simple approach, more advanced methods are often necessary for complex queries and large datasets.
    *   **Routers**: Modules that use an LLM to make decisions about how to handle a query by selecting one or more "choices," such as different data sources or query engines/retrievers. A **RouterQueryEngine** or **RouterRetriever** can be used to route the query to the most appropriate underlying system (e.g., deciding between a summary index for overview questions and a vector index for specific facts).
    *   **Recursive Retrieval**: Executing linked query engines or retrievers if a retrieved node (like an Index Node representing a table summary) points to them. This allows drilling down from higher-level summaries to detailed underlying data sources.
    *   **Task-Specific Retrieval**: Adapting the retrieval strategy based on the user's task, such as retrieving differently for fact-finding, summarization, or comparison queries. LlamaIndex provides modules like routers and data agents to support this dynamic retrieval.
    *   **Structured Retrieval**: Using structured information like metadata filters or document hierarchies in conjunction with semantic search to improve retrieval accuracy, especially over large document sets.
    *   **Postprocessing**: Applying transformations to the retrieved nodes before they are passed to the LLM. An example is the **Metadata Replacement PostProcessor**, which can replace a retrieved sentence with the larger "window" of surrounding text stored in its metadata, providing more context for the LLM.
*   **Query Planning**: For complex, multi-part queries, breaking the query down into smaller, parallelizable sub-queries that can be executed independently against different RAG pipelines or tools.
*   **Memory**: Integrating conversation history into the retrieval process, especially in agentic systems. This allows the system to understand the context of the current query based on previous interactions. Memory can involve various types, including short-term buffers and long-term storage for facts or past messages.
*   **Tool Use**: Allowing the LLM to call external tools or APIs (which can wrap query engines, data loaders, or perform other actions) to gather additional information or perform specific tasks as part of the reasoning process. The LLM interprets the user's request and determines the necessary parameters for tool calls. **QueryEngineTool** can wrap query engines, allowing the agent to use them as tools. Utility tools like **OnDemandLoaderTool** and **LoadAndSearchToolSpec** help handle large responses from external APIs by indexing and querying the results on demand. Tools can be configured to return results directly, ending the reasoning loop.
*   **LLM Processing and Response Synthesis**: The retrieved context (potentially augmented by memory and tool results) is passed to the LLM along with the user's query. The LLM then synthesizes a coherent and relevant response based on this information.

These components highlight how a RAG workflow evolves from a basic system into a more advanced agentic one capable of handling complex data and queries.