#!/usr/bin/env python3
"""
Minimal test script for section-based parser functionality.
"""

import sys
from pathlib import Path

# Add current directory to path
sys.path.append(str(Path(__file__).parent))

try:
    from data_processing.section_parser import LandDeedSectionParser
    from data_processing.models import DatasetConfig, SimpleDocument
    print("âœ… Successfully imported section parser modules")
except ImportError as e:
    print(f"âŒ Import error: {e}")
    sys.exit(1)


def test_section_parser():
    """Test the section parser with a sample document."""
    print("\nğŸ”§ Testing Section-Based Parser")
    print("="*50)
    
    # Sample land deed document text
    sample_text = """# à¸šà¸±à¸™à¸—à¸¶à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹‚à¸‰à¸™à¸”à¸—à¸µà¹ˆà¸”à¸´à¸™ (Land Deed Record)

## à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹‚à¸‰à¸™à¸” (Deed Information)
- à¸£à¸«à¸±à¸ªà¹‚à¸‰à¸™à¸”: deed_12345
- à¸›à¸£à¸°à¹€à¸ à¸—à¹‚à¸‰à¸™à¸”: à¹‚à¸‰à¸™à¸”à¸—à¸µà¹ˆà¸”à¸´à¸™
- à¹€à¸¥à¸‚à¸—à¸µà¹ˆà¹‚à¸‰à¸™à¸”: 12345

## à¸—à¸µà¹ˆà¸•à¸±à¹‰à¸‡ (Location)
- à¸ˆà¸±à¸‡à¸«à¸§à¸±à¸”: à¸à¸£à¸¸à¸‡à¹€à¸—à¸à¸¡à¸«à¸²à¸™à¸„à¸£
- à¸­à¸³à¹€à¸ à¸­: à¸§à¸±à¸’à¸™à¸²
- à¸•à¸³à¸šà¸¥: à¸¥à¸¸à¸¡à¸à¸´à¸™à¸µ

## à¸‚à¸™à¸²à¸”à¸à¸·à¹‰à¸™à¸—à¸µà¹ˆ (Area Measurements)
- à¹€à¸™à¸·à¹‰à¸­à¸—à¸µà¹ˆ: 2 à¹„à¸£à¹ˆ 1 à¸‡à¸²à¸™ 50 à¸•à¸£.à¸§.
- à¸à¸·à¹‰à¸™à¸—à¸µà¹ˆà¸£à¸§à¸¡ (à¸•à¸£.à¸¡.): 3600.0
"""
    
    # Sample metadata
    metadata = {
        'deed_serial_no': '12345',
        'deed_type': 'à¹‚à¸‰à¸™à¸”à¸—à¸µà¹ˆà¸”à¸´à¸™',
        'province': 'à¸à¸£à¸¸à¸‡à¹€à¸—à¸à¸¡à¸«à¸²à¸™à¸„à¸£',
        'district': 'à¸§à¸±à¸’à¸™à¸²',
        'doc_id': 'deed_12345'
    }
    
    # Create simple document
    simple_doc = SimpleDocument(text=sample_text, metadata=metadata)
    
    # Create section parser
    config = DatasetConfig(
        name="test_config",
        description="Test configuration",
        field_mappings=[]
    )
    
    parser = LandDeedSectionParser(
        dataset_config=config,
        chunk_size=512,
        chunk_overlap=50,
        min_section_size=50
    )
    
    print("ğŸ“„ Parsing sample document...")
    
    # Parse document
    try:
        nodes = parser.parse_simple_document_to_sections(simple_doc)
        print(f"âœ… Successfully created {len(nodes)} section chunks")
        
        # Display results
        for i, node in enumerate(nodes):
            chunk_type = node.metadata.get('chunk_type', 'unknown')
            section = node.metadata.get('section', 'unknown')
            text_length = len(node.text)
            
            print(f"  {i+1}. [{chunk_type}] {section} ({text_length} chars)")
            
            # Show first 100 chars of text
            preview = node.text[:100].replace('\n', ' ')
            if len(node.text) > 100:
                preview += "..."
            print(f"      Preview: {preview}")
            print()
        
        # Get statistics
        stats = parser.get_chunking_statistics(nodes)
        print("ğŸ“Š Statistics:")
        print(f"  Total chunks: {stats['total_chunks']}")
        print(f"  Chunk types: {stats['chunk_types']}")
        print(f"  Sections: {stats['sections']}")
        print(f"  Average size: {stats['average_chunk_size']:.1f} chars")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error parsing document: {e}")
        return False


if __name__ == "__main__":
    print("ğŸš€ Section Parser Test")
    success = test_section_parser()
    
    if success:
        print("\nâœ… Section parser test completed successfully!")
        print("\nğŸ“‹ What was tested:")
        print("- Section pattern matching")
        print("- Key info chunk creation")
        print("- Section-specific chunk generation")
        print("- Metadata preservation")
        print("- Statistics generation")
    else:
        print("\nâŒ Section parser test failed!")
    
    print("\nğŸ¯ Next: Run the full embedding pipeline with section chunking") 