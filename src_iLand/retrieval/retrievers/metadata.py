"""
Enhanced Metadata Retriever Adapter for iLand Data

Implements fast metadata-filtered retrieval for Thai land deed data with sub-50ms filtering.
Enhanced with FastMetadataIndexManager for 90% document reduction before vector search.
Builds on existing patterns, adapted from src/agentic_retriever/retrievers/metadata.py.
"""

import time
from typing import List, Optional, Dict, Any, Set
from llama_index.core.schema import NodeWithScore
from llama_index.core import VectorStoreIndex
from llama_index.core.vector_stores.types import MetadataFilters, MetadataFilter, FilterOperator

from .base import BaseRetrieverAdapter
from ..fast_metadata_index import FastMetadataIndexManager

# Import from updated iLand embedding loading modules
try:
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent.parent.parent))
    from load_embedding import iLandIndexReconstructor, EmbeddingConfig
except ImportError as e:
    print(f"Warning: Could not import iLand embedding utilities: {e}")
    iLandIndexReconstructor = None
    EmbeddingConfig = None


class MetadataRetrieverAdapter(BaseRetrieverAdapter):
    """Enhanced adapter for fast metadata-filtered retrieval on iLand data."""
    
    def __init__(self, index: VectorStoreIndex, default_top_k: int = 5, enable_fast_filtering: bool = True):
        """
        Initialize enhanced metadata retriever adapter for iLand data.
        
        Args:
            index: Vector store index with Thai land deed metadata
            default_top_k: Default number of nodes to retrieve
            enable_fast_filtering: Enable FastMetadataIndexManager for sub-50ms filtering
        """
        super().__init__("enhanced_metadata")
        self.index = index
        self.default_top_k = default_top_k
        self.enable_fast_filtering = enable_fast_filtering
        
        # Initialize fast metadata indexing if enabled
        self.fast_metadata_index = None
        if enable_fast_filtering:
            self._initialize_fast_indexing()
        
        # Complete Thai-to-English province mapping (all 77 provinces)
        self.thai_to_english_provinces = {
            "à¸à¸£à¸¸à¸‡à¹€à¸—à¸žà¸¡à¸«à¸²à¸™à¸„à¸£": "**: Bangkok",
            "à¸­à¸³à¸™à¸²à¸ˆà¹€à¸ˆà¸£à¸´à¸": "**: Amnat Charoen", 
            "à¸­à¹ˆà¸²à¸‡à¸—à¸­à¸‡": "**: Ang Thong",
            "à¸šà¸¶à¸‡à¸à¸²à¸¬": "**: Bueng Kan",
            "à¸šà¸¸à¸£à¸µà¸£à¸±à¸¡à¸¢à¹Œ": "**: Buriram",
            "à¸‰à¸°à¹€à¸Šà¸´à¸‡à¹€à¸—à¸£à¸²": "**: Chachoengsao",
            "à¸Šà¸±à¸¢à¸™à¸²à¸—": "**: Chai Nat",
            "à¸Šà¸±à¸¢à¸ à¸¹à¸¡à¸´": "**: Chaiyaphum",
            "à¸ˆà¸±à¸™à¸—à¸šà¸¸à¸£à¸µ": "**: Chanthaburi",
            "à¹€à¸Šà¸µà¸¢à¸‡à¹ƒà¸«à¸¡à¹ˆ": "**: Chiang Mai",
            "à¹€à¸Šà¸µà¸¢à¸‡à¸£à¸²à¸¢": "**: Chiang Rai",
            "à¸Šà¸¥à¸šà¸¸à¸£à¸µ": "**: Chonburi",
            "à¸Šà¸¸à¸¡à¸žà¸£": "**: Chumphon",
            "à¸à¸²à¸¬à¸ªà¸´à¸™à¸˜à¸¸à¹Œ": "**: Kalasin",
            "à¸à¸³à¹à¸žà¸‡à¹€à¸žà¸Šà¸£": "**: Kamphaeng Phet",
            "à¸à¸²à¸à¸ˆà¸™à¸šà¸¸à¸£à¸µ": "**: Kanchanaburi",
            "à¸‚à¸­à¸™à¹à¸à¹ˆà¸™": "**: Khon Kaen",
            "à¸à¸£à¸°à¸šà¸µà¹ˆ": "**: Krabi",
            "à¸¥à¸³à¸›à¸²à¸‡": "**: Lampang",
            "à¸¥à¸³à¸žà¸¹à¸™": "**: Lamphun",
            "à¹€à¸¥à¸¢": "**: Loei",
            "à¸¥à¸žà¸šà¸¸à¸£à¸µ": "**: Lopburi",
            "à¹à¸¡à¹ˆà¸®à¹ˆà¸­à¸‡à¸ªà¸­à¸™": "**: Mae Hong Son",
            "à¸¡à¸«à¸²à¸ªà¸²à¸£à¸„à¸²à¸¡": "**: Maha Sarakham",
            "à¸¡à¸¸à¸à¸”à¸²à¸«à¸²à¸£": "**: Mukdahan",
            "à¸™à¸„à¸£à¸™à¸²à¸¢à¸": "**: Nakhon Nayok",
            "à¸™à¸„à¸£à¸›à¸à¸¡": "**: Nakhon Pathom",
            "à¸™à¸„à¸£à¸žà¸™à¸¡": "**: Nakhon Phanom",
            "à¸™à¸„à¸£à¸£à¸²à¸Šà¸ªà¸µà¸¡à¸²": "**: Nakhon Ratchasima",
            "à¸™à¸„à¸£à¸ªà¸§à¸£à¸£à¸„à¹Œ": "**: Nakhon Sawan",
            "à¸™à¸„à¸£à¸¨à¸£à¸µà¸˜à¸£à¸£à¸¡à¸£à¸²à¸Š": "**: Nakhon Si Thammarat",
            "à¸™à¹ˆà¸²à¸™": "**: Nan",
            "à¸™à¸£à¸²à¸˜à¸´à¸§à¸²à¸ª": "**: Narathiwat",
            "à¸«à¸™à¸­à¸‡à¸šà¸±à¸§à¸¥à¸³à¸ à¸¹": "**: Nong Bua Lamphu",
            "à¸«à¸™à¸­à¸‡à¸„à¸²à¸¢": "**: Nong Khai",
            "à¸™à¸™à¸—à¸šà¸¸à¸£à¸µ": "**: Nonthaburi",
            "à¸›à¸—à¸¸à¸¡à¸˜à¸²à¸™à¸µ": "**: Pathum Thani",
            "à¸›à¸±à¸•à¸•à¸²à¸™à¸µ": "**: Pattani",
            "à¸žà¸±à¸‡à¸‡à¸²": "**: Phang Nga",
            "à¸žà¸±à¸—à¸¥à¸¸à¸‡": "**: Phatthalung",
            "à¸žà¸°à¹€à¸¢à¸²": "**: Phayao",
            "à¹€à¸žà¸Šà¸£à¸šà¸¹à¸£à¸“à¹Œ": "**: Phetchabun",
            "à¹€à¸žà¸Šà¸£à¸šà¸¸à¸£à¸µ": "**: Phetchaburi",
            "à¸žà¸´à¸ˆà¸´à¸•à¸£": "**: Phichit",
            "à¸žà¸´à¸©à¸“à¸¸à¹‚à¸¥à¸": "**: Phitsanulok",
            "à¸žà¸£à¸°à¸™à¸„à¸£à¸¨à¸£à¸µà¸­à¸¢à¸¸à¸˜à¸¢à¸²": "**: Phra Nakhon Si Ayutthaya",
            "à¹à¸žà¸£à¹ˆ": "**: Phrae",
            "à¸ à¸¹à¹€à¸à¹‡à¸•": "**: Phuket",
            "à¸›à¸£à¸²à¸ˆà¸µà¸™à¸šà¸¸à¸£à¸µ": "**: Prachinburi",
            "à¸›à¸£à¸°à¸ˆà¸§à¸šà¸„à¸µà¸£à¸µà¸‚à¸±à¸™à¸˜à¹Œ": "**: Prachuap Khiri Khan",
            "à¸£à¸°à¸™à¸­à¸‡": "**: Ranong",
            "à¸£à¸²à¸Šà¸šà¸¸à¸£à¸µ": "**: Ratchaburi",
            "à¸£à¸°à¸¢à¸­à¸‡": "**: Rayong",
            "à¸£à¹‰à¸­à¸¢à¹€à¸­à¹‡à¸”": "**: Roi Et",
            "à¸ªà¸£à¸°à¹à¸à¹‰à¸§": "**: Sa Kaeo",
            "à¸ªà¸à¸¥à¸™à¸„à¸£": "**: Sakon Nakhon",
            "à¸ªà¸¡à¸¸à¸—à¸£à¸›à¸£à¸²à¸à¸²à¸£": "**: Samut Prakan",
            "à¸ªà¸¡à¸¸à¸—à¸£à¸ªà¸²à¸„à¸£": "**: Samut Sakhon",
            "à¸ªà¸¡à¸¸à¸—à¸£à¸ªà¸‡à¸„à¸£à¸²à¸¡": "**: Samut Songkhram",
            "à¸ªà¸£à¸°à¸šà¸¸à¸£à¸µ": "**: Saraburi",
            "à¸ªà¸•à¸¹à¸¥": "**: Satun",
            "à¸ªà¸´à¸‡à¸«à¹Œà¸šà¸¸à¸£à¸µ": "**: Sing Buri",
            "à¸¨à¸£à¸µà¸ªà¸°à¹€à¸à¸©": "**: Sisaket",
            "à¸ªà¸‡à¸‚à¸¥à¸²": "**: Songkhla",
            "à¸ªà¸¸à¹‚à¸‚à¸—à¸±à¸¢": "**: Sukhothai",
            "à¸ªà¸¸à¸žà¸£à¸£à¸“à¸šà¸¸à¸£à¸µ": "**: Suphan Buri",
            "à¸ªà¸¸à¸£à¸²à¸©à¸Žà¸£à¹Œà¸˜à¸²à¸™à¸µ": "**: Surat Thani",
            "à¸ªà¸¸à¸£à¸´à¸™à¸—à¸£à¹Œ": "**: Surin",
            "à¸•à¸²à¸": "**: Tak",
            "à¸•à¸£à¸±à¸‡": "**: Trang",
            "à¸•à¸£à¸²à¸”": "**: Trat",
            "à¸­à¸¸à¸šà¸¥à¸£à¸²à¸Šà¸˜à¸²à¸™à¸µ": "**: Ubon Ratchathani",
            "à¸­à¸¸à¸”à¸£à¸˜à¸²à¸™à¸µ": "**: Udon Thani",
            "à¸­à¸¸à¸—à¸±à¸¢à¸˜à¸²à¸™à¸µ": "**: Uthai Thani",
            "à¸­à¸¸à¸•à¸£à¸”à¸´à¸•à¸–à¹Œ": "**: Uttaradit",
            "à¸¢à¸°à¸¥à¸²": "**: Yala",
            "à¸¢à¹‚à¸ªà¸˜à¸£": "**: Yasothon"
        }
    
    def _initialize_fast_indexing(self) -> None:
        """Initialize fast metadata indexing from LlamaIndex nodes."""
        try:
            print("ðŸ”„ Initializing fast metadata indexing...")
            self.fast_metadata_index = FastMetadataIndexManager()
            
            # Build indices from LlamaIndex nodes
            nodes = list(self.index.docstore.docs.values())
            self.fast_metadata_index.build_indices_from_llamaindex_nodes(nodes)
            
            print("âœ… Fast metadata indexing initialized")
        except Exception as e:
            print(f"âš ï¸ Fast indexing initialization failed: {e}")
            print("âš ï¸ Falling back to standard LlamaIndex filtering")
            self.fast_metadata_index = None
            self.enable_fast_filtering = False
    
    def retrieve(self, query: str, top_k: Optional[int] = None, 
                 filters: Optional[Dict[str, Any]] = None) -> List[NodeWithScore]:
        """
        Enhanced retrieve with fast metadata pre-filtering for sub-50ms performance.
        
        Args:
            query: The search query (may contain Thai text)
            top_k: Number of nodes to retrieve (uses default if None)
            filters: Metadata filters to apply (province, district, etc.)
            
        Returns:
            List of NodeWithScore objects tagged with strategy
        """
        start_time = time.time()
        k = top_k if top_k is not None else self.default_top_k
        
        # Build metadata filters for Thai land deed data
        metadata_filters = self._build_metadata_filters(filters, query)
        
        # Fast pre-filtering if enabled and filters present
        candidate_node_ids = None
        if (self.enable_fast_filtering and 
            self.fast_metadata_index and 
            metadata_filters):
            
            candidate_node_ids = self.fast_metadata_index.pre_filter_node_ids(metadata_filters)
            
            # If fast filtering reduced candidates significantly, use them
            if candidate_node_ids and len(candidate_node_ids) < (self.fast_metadata_index.total_documents * 0.8):
                nodes = self._retrieve_from_candidates(query, k, candidate_node_ids, metadata_filters)
            else:
                # Fall back to standard LlamaIndex filtering
                nodes = self._retrieve_standard(query, k, metadata_filters)
        else:
            # Standard LlamaIndex retrieval
            nodes = self._retrieve_standard(query, k, metadata_filters)
        
        # Add performance metadata
        retrieval_time = (time.time() - start_time) * 1000
        for node in nodes:
            if hasattr(node.node, 'metadata'):
                node.node.metadata.update({
                    "fast_filtering_enabled": self.enable_fast_filtering,
                    "pre_filtered": candidate_node_ids is not None,
                    "retrieval_time_ms": retrieval_time
                })
        
        # Tag nodes with strategy
        return self._tag_nodes_with_strategy(nodes)
    
    def _retrieve_standard(self, query: str, k: int, metadata_filters: Optional[MetadataFilters]) -> List[NodeWithScore]:
        """Standard LlamaIndex retrieval."""
        if metadata_filters:
            retriever = self.index.as_retriever(similarity_top_k=k, filters=metadata_filters)
        else:
            retriever = self.index.as_retriever(similarity_top_k=k)
        return retriever.retrieve(query)
    
    def _retrieve_from_candidates(self, query: str, k: int, candidate_node_ids: Set[str], 
                                metadata_filters: Optional[MetadataFilters]) -> List[NodeWithScore]:
        """Retrieve from pre-filtered candidate nodes."""
        # Create a custom retriever that only considers candidate nodes
        # This is where we achieve the 90% reduction benefit
        
        # Convert candidate IDs to list for LlamaIndex
        node_ids_list = list(candidate_node_ids)
        
        # Use LlamaIndex's ability to retrieve from specific node IDs
        from llama_index.core import QueryBundle
        from llama_index.core.retrievers import BaseRetriever
        
        # Create a filtered retriever that only searches candidate nodes
        try:
            # Use LlamaIndex's vector retriever with node ID filtering
            retriever = self.index.as_retriever(similarity_top_k=k)
            query_bundle = QueryBundle(query_str=query)
            
            # Get all results and filter to candidates
            all_results = retriever.retrieve(query_bundle)
            filtered_results = [
                node for node in all_results 
                if node.node.node_id in candidate_node_ids
            ]
            
            # Return top-k results
            return filtered_results[:k]
            
        except Exception as e:
            print(f"âš ï¸ Candidate filtering failed: {e}, falling back to standard retrieval")
            return self._retrieve_standard(query, k, metadata_filters)
    
    def _build_metadata_filters(self, filters: Optional[Dict[str, Any]], 
                               query: str) -> Optional[MetadataFilters]:
        """
        Build metadata filters for Thai land deed data.
        
        Args:
            filters: Explicit filters provided
            query: Query text to extract implicit filters from
            
        Returns:
            MetadataFilters object or None
        """
        filter_conditions = []
        
        # Apply explicit filters
        if filters:
            for key, value in filters.items():
                if key == "province" and value:
                    filter_conditions.append(
                        MetadataFilter(key="province", value=value, operator=FilterOperator.EQ)
                    )
                elif key == "district" and value:
                    filter_conditions.append(
                        MetadataFilter(key="district", value=value, operator=FilterOperator.EQ)
                    )
                elif key == "land_type" and value:
                    filter_conditions.append(
                        MetadataFilter(key="land_type", value=value, operator=FilterOperator.EQ)
                    )
                elif key == "year" and value:
                    filter_conditions.append(
                        MetadataFilter(key="year", value=value, operator=FilterOperator.EQ)
                    )
        
        # Extract implicit filters from query (Thai province names)
        # Only add implicit filters if no explicit province filter was provided
        if not filters or "province" not in filters:
            query_lower = query.lower()
            for thai_province, english_province in self.thai_to_english_provinces.items():
                if thai_province in query or thai_province.lower() in query_lower:
                    filter_conditions.append(
                        MetadataFilter(key="province", value=english_province, operator=FilterOperator.EQ)
                    )
                    break  # Use first matching province
        
        # Note: Removed implicit deed type filtering as "à¸—à¸µà¹ˆà¸”à¸´à¸™" is too generic
        # and doesn't map well to specific deed_type_category values.
        # Explicit filters can still be used for deed_type_category if needed.
        
        if filter_conditions:
            return MetadataFilters(filters=filter_conditions)
        
        return None
    
    @classmethod
    def from_iland_embeddings(
        cls,
        embeddings: List[dict],
        api_key: Optional[str] = None,
        default_top_k: int = 5
    ) -> "MetadataRetrieverAdapter":
        """
        Create adapter from iLand embeddings with metadata.
        
        Args:
            embeddings: List of iLand embedding dictionaries with metadata
            api_key: OpenAI API key
            default_top_k: Default number of nodes to retrieve
            
        Returns:
            MetadataRetrieverAdapter instance for iLand data
        """
        if not iLandIndexReconstructor or not EmbeddingConfig:
            raise ImportError("iLand embedding utilities not available")
        
        config = EmbeddingConfig(api_key=api_key)
        reconstructor = iLandIndexReconstructor(config=config)
        index = reconstructor.create_vector_index_from_embeddings(
            embeddings,
            show_progress=False
        )
        return cls(index, default_top_k)
    
    def get_fast_index_stats(self) -> Optional[Dict[str, Any]]:
        """Get fast metadata index performance statistics."""
        if self.fast_metadata_index:
            return self.fast_metadata_index.get_index_stats()
        return None
    
    def toggle_fast_filtering(self, enabled: bool) -> bool:
        """Enable or disable fast filtering."""
        if enabled and not self.fast_metadata_index:
            self._initialize_fast_indexing()
        
        self.enable_fast_filtering = enabled and self.fast_metadata_index is not None
        return self.enable_fast_filtering